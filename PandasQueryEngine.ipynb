{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DEGxdQAn4fVVHtYNlX4KvNfJCSqaTpF9",
      "authorship_tag": "ABX9TyN7TjIDFYkpUTW3g1+OJt2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navalepratham18/LLM-Powered-Pandas-Query-Engine/blob/main/PandasQueryEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-Powered Pandas Query Engine\n",
        "\n",
        "This notebook uses the `PandasQueryEngine` to create a data analysis chatbot. This approach is ideal for structured tabular data (like our Excel files) as it leverages a Large Language Model (LLM) to dynamically generate and execute Python (Pandas) code, enabling precise calculations and filtering.\n",
        "\n",
        "### 1. Configuration & Data Preparation\n",
        "- **Setup:** We first install the required libraries and configure `Gemini 1.5 Pro` as our reasoning engine. The LLM's role is to act as an on-demand programmer.\n",
        "- **Data Unification:** All individual Excel files from Google Drive are loaded and concatenated into a single, master Pandas DataFrame. This provides a unified, in-memory table for the engine to query.\n",
        "\n",
        "### 2. Contextual Querying via Code Generation\n",
        "This engine's core logic does not use vectorization. Instead, it operates through a three-step process for each query:\n",
        "1.  **Prompt Construction (Context):** When a user asks a question, the engine constructs a detailed prompt for the Gemini API. This prompt includes the user's query and, most importantly, the **schema of the DataFrame** (all column names and their data types). This schema provides the necessary context for the LLM.\n",
        "2.  **LLM-Powered Code Generation:** Using this context, the Gemini LLM analyzes the user's intent and generates a string of Pandas code designed to answer the question by manipulating the DataFrame.\n",
        "3.  **Local Execution:** This generated code is executed locally within the Colab environment on the master DataFrame. The numerical or factual result is then used by the LLM to formulate the final, human-readable answer.\n",
        "\n",
        "### 3. Stateless Interaction\n",
        "The `PandasQueryEngine` is re-initialized inside the `while` loop for every new question. This makes the system **stateless**, ensuring that each query is treated as a fresh, independent analysis without any memory of previous interactions, which is critical for accuracy."
      ],
      "metadata": {
        "id": "orUL3QyzXvnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f-d9i9xqond",
        "outputId": "c41ad462-2305-4b9a-8d59-011d06afc524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing libraries... This may take a minute.\n",
            "Installation complete.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted.\n",
            "API Key loaded successfully.\n",
            "LLM configured to use Gemini 1.5 Pro.\n",
            "\n",
            "Loading and combining all Excel files from /content/drive/MyDrive/data...\n",
            "Successfully loaded and combined 1 files into a single DataFrame with 27863 rows.\n",
            "\n",
            "--- Start Chatting With Your Data ---\n",
            "Ask a question about your data (or type 'exit' to quit): What was the density for the observation ID 1900083_26/08/2001 at a depth of 759.3?\n",
            "\n",
            "Response:\n",
            "12.464110217851632\n",
            "\n",
            "==================================================\n",
            "\n",
            "Ask a question about your data (or type 'exit' to quit): what was the average temperature throughout the year 2001?\n",
            "\n",
            "Response:\n",
            "12.464110217851632\n",
            "\n",
            "==================================================\n",
            "\n",
            "Ask a question about your data (or type 'exit' to quit): exit\n",
            "Exiting. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# --- 1. INSTALL LIBRARIES ---\n",
        "print(\"Installing libraries... This may take a minute.\")\n",
        "%pip install llama-index llama-index-llms-google-genai pandas openpyxl &> /dev/null\n",
        "%pip install llama-index-experimental &> /dev/null\n",
        "print(\"Installation complete.\")\n",
        "\n",
        "\n",
        "# --- 2. MOUNT GOOGLE DRIVE & SETUP ---\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import userdata, drive\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.google_genai import GoogleGenAI\n",
        "from llama_index.experimental.query_engine import PandasQueryEngine\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# Securely import your Google API key\n",
        "try:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "except userdata.SecretNotFoundError as e:\n",
        "    print(\"Secret not found. Please add your GOOGLE_API_KEY to Colab's secrets.\")\n",
        "    raise e\n",
        "print(\"API Key loaded successfully.\")\n",
        "\n",
        "\n",
        "# --- 3. CONFIGURE THE LLM ---\n",
        "Settings.llm = GoogleGenAI(model_name=\"models/gemini-1.5-pro-latest\")\n",
        "print(\"LLM configured to use Gemini 1.5 Pro.\")\n",
        "\n",
        "\n",
        "# --- 4. LOAD ALL EXCEL FILES INTO A SINGLE PANDAS DATAFRAME ---\n",
        "INPUT_DIR = \"/content/drive/MyDrive/data\"\n",
        "print(f\"\\nLoading and combining all Excel files from {INPUT_DIR}...\")\n",
        "\n",
        "excel_files = [os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith('.xlsx')]\n",
        "list_of_dfs = [pd.read_excel(file) for file in excel_files]\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "\n",
        "print(f\"Successfully loaded and combined {len(excel_files)} files into a single DataFrame with {len(df)} rows.\")\n",
        "\n",
        "\n",
        "# --- 5. ASK QUESTIONS! ---\n",
        "print(\"\\n--- Start Chatting With Your Data ---\")\n",
        "while True:\n",
        "    try:\n",
        "        query = input(\"Ask a question about your data (or type 'exit' to quit): \")\n",
        "        if query.lower() == 'exit':\n",
        "            print(\"Exiting. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # We create a new, stateless query engine for every single query.\n",
        "        # This prevents the engine from remembering previous answers.\n",
        "        # print(\"\\nCreating a fresh query engine...\")\n",
        "        query_engine = PandasQueryEngine(df=df, llm=Settings.llm, verbose=True)\n",
        "\n",
        "        # print(\"Thinking...\")\n",
        "        # response = query_engine.query(query)\n",
        "\n",
        "        print(\"\\nResponse:\")\n",
        "        print(str(response))\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    except EOFError:\n",
        "        print(\"\\nExiting due to input interruption.\")\n",
        "        break"
      ]
    }
  ]
}